{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/Yes_we_GAN/blob/master/Fashion_DCGAN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "14vb70Ys_sxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "KlRx5ymdZG0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "tHZUZmOUNEoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dccce1e-74f9-44cc-d509-ad770de39b9e"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Flatten\n",
        "from keras.layers import UpSampling2D, Conv2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uvvPV_WIZoR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the generator"
      ]
    },
    {
      "metadata": {
        "id": "6gqJ4ZrmNHve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_size, img_shape):\n",
        "  \n",
        "  filters = 512\n",
        "  k_size = 5, 5\n",
        "  k_init = RandomNormal(0, 0.02)\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  \n",
        "  x = Dense(4*4*filters, activation='relu', kernel_initializer=k_init)(noise)\n",
        "  x = Reshape((4, 4, filters))(x)  # 4, 4\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 8, 8\n",
        "  \n",
        "  x = Conv2D(filters // 2, k_size, padding='same', activation='relu', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 16, 16\n",
        "  \n",
        "  x = Conv2D(filters // 4, k_size, padding='same', activation='relu', kernel_initializer=k_init)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D()(x)  # 32, 32\n",
        "  \n",
        "  img = Conv2D(1, k_size, padding='same', activation='tanh', kernel_initializer=k_init)(x)\n",
        "  \n",
        "  generator = Model(noise, img)\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooEwRbP8eLgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "UysJTIlPOlZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "  \n",
        "  filters = 512\n",
        "  k_size = 5, 5\n",
        "  k_init = RandomNormal(0, 0.02)\n",
        "  \n",
        "  img = Input(img_shape)  # 32, 32\n",
        "  \n",
        "  x = Conv2D(filters // 4, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(img)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 16, 16\n",
        "  \n",
        "  x = Conv2D(filters // 2, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(img)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 8, 8\n",
        "  \n",
        "  x = Conv2D(filters, k_size, strides=(2, 2), padding='same', kernel_initializer=k_init)(img)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(0.2)(x)  # 4, 4\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  validity = Dense(1, activation='sigmoid')(x)\n",
        "  \n",
        "  discriminator = Model(img, validity)\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxDM6ldueOte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to compile the models"
      ]
    },
    {
      "metadata": {
        "id": "gEfTuy93PRNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_compiled_models(generator, discriminator, noise_size):\n",
        "  \n",
        "  optimizer = Adam(0.0002, 0.5)\n",
        "  \n",
        "  discriminator.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  discriminator.trainable = False\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  img = generator(noise)\n",
        "  validity = discriminator(img)\n",
        "  combined = Model(noise, validity)\n",
        "  \n",
        "  combined.compile(optimizer, loss='binary_crossentropy')\n",
        "  \n",
        "  return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocu71YfmeSIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample and save generated images"
      ]
    },
    {
      "metadata": {
        "id": "X4-ejg8UTwqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_imgs(generator, noise_size, step, plot_img=True, cond=False, num_classes=10):\n",
        "  np.random.seed(0)\n",
        "  \n",
        "  r, c = num_classes, 10\n",
        "  if cond:\n",
        "    noise = np.random.normal(0, 1, (c, noise_size))\n",
        "    noise = np.tile(noise, (r, 1))\n",
        "\n",
        "    sampled_labels = np.arange(r).reshape(-1, 1)\n",
        "    sampled_labels = to_categorical(sampled_labels, r)\n",
        "    sampled_labels = np.repeat(sampled_labels, c, axis=0)\n",
        "\n",
        "    imgs = generator.predict([noise, sampled_labels])\n",
        "  else:\n",
        "    noise = np.random.normal(0, 1, (r*c, noise_size))\n",
        "    imgs = generator.predict_on_batch(noise)\n",
        "  \n",
        "  imgs = imgs / 2 + 0.5\n",
        "  imgs = np.reshape(imgs, [r, c, imgs.shape[1], imgs.shape[2], -1])\n",
        "  \n",
        "  figsize = 1 * c, 1 * r\n",
        "  fig, axs = plt.subplots(r, c, figsize=figsize)\n",
        "  \n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      img = imgs[i, j] if len(imgs.shape) == 4 else imgs[i, j, :, :, 0]\n",
        "      axs[i, j].imshow(img, cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  fig.savefig(f'/content/images/{step}.png')\n",
        "  if plot_img:\n",
        "    plt.show()\n",
        "  plt.close()\n",
        "  \n",
        "  np.random.seed(None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3ofIxpleVoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to train the models"
      ]
    },
    {
      "metadata": {
        "id": "wHI7xwGMQRAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(models, noise_size, img_shape, batch_size, steps):\n",
        "  \n",
        "  generator, discriminator, combined = models\n",
        "  #get real data\n",
        "  (X_train, _), (X_val, _) = fashion_mnist.load_data()\n",
        "  fashion_mnist_imgs = np.concatenate((X_train, X_val)) / 127.5 - 1\n",
        "  fashion_mnist_imgs = np.pad(fashion_mnist_imgs, ((0, 0), (2, 2), (2, 2)), 'constant', constant_values=-1)\n",
        "  fashion_mnist_imgs = np.expand_dims(fashion_mnist_imgs, axis=-1)\n",
        "  \n",
        "  for step in range(1, steps + 1):\n",
        "    # train discriminator\n",
        "    inds = np.random.randint(0, fashion_mnist_imgs.shape[0], batch_size)\n",
        "    real_imgs = fashion_mnist_imgs[inds]\n",
        "    real_validity = np.ones(batch_size)\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_validity = np.zeros(batch_size)\n",
        "    \n",
        "    r_loss = discriminator.train_on_batch(real_imgs, real_validity)\n",
        "    g_loss = discriminator.train_on_batch(gen_imgs, gen_validity)\n",
        "    disc_loss = np.add(r_loss, g_loss) / 2\n",
        "    \n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_validity = np.ones(batch_size)\n",
        "    gen_loss = combined.train_on_batch(noise, gen_validity)\n",
        "    \n",
        "    #print progress\n",
        "    if step % 50 == 0:\n",
        "      print('step: %d, D_loss: %f, D_accuracy: %.2f%%, G_loss: %f' % (step, disc_loss[0],\n",
        "                                                                      disc_loss[1] * 100, gen_loss))\n",
        "    \n",
        "    # save_samples\n",
        "    if step % 200 == 0:\n",
        "      sample_imgs(generator, noise_size, step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHnx_qUceZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "1-ePrmDUVBYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%rm -r /content/images\n",
        "%mkdir /content/images\n",
        "noise_size = 100\n",
        "img_shape = 32, 32, 1\n",
        "batch_size = 64\n",
        "steps = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhkkM5ctecbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the models"
      ]
    },
    {
      "metadata": {
        "id": "FCr5cDHOZCdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = build_generator(noise_size, img_shape)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "compiled_models = get_compiled_models(generator, discriminator, noise_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTkuRejSefba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ]
    },
    {
      "metadata": {
        "id": "JznD-Lt6Y2h_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32371
        },
        "outputId": "6493a1c0-d997-42c1-87ac-ec1662d57f9a"
      },
      "cell_type": "code",
      "source": [
        "train(compiled_models, noise_size, img_shape, batch_size, steps)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzPwRKZzL4bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot resutls"
      ]
    },
    {
      "metadata": {
        "id": "PS-SEYwnKHWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install import_ipynb\n",
        "%cd /content\n",
        "%rm -r /content/0a16ae419d9eba160ddb4f48862fb9e2\n",
        "!git clone https://gist.github.com/dkatsios/0a16ae419d9eba160ddb4f48862fb9e2.git\n",
        "%cd /content/0a16ae419d9eba160ddb4f48862fb9e2\n",
        "import import_ipynb\n",
        "from IPython.display import HTML\n",
        "from AnimationDisplay import plot_results\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4AUQJmtigZ4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "22b4b37b-43e9-4602-bc53-fe9402106ea0"
      },
      "cell_type": "code",
      "source": [
        "path = '/content/images/{}.png'\n",
        "iterator = range(200, steps+1, 200)\n",
        "HTML(plot_results(path, iterator).to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaDzs7MYQ3ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download images and generator"
      ]
    },
    {
      "metadata": {
        "id": "mr9q_1QsQ60o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen_path = '/content/gen.h5'\n",
        "generator.save(gen_path)\n",
        "from google.colab import files\n",
        "files.download(gen_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}